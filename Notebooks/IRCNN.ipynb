{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IRCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1r6UPaPYCC63LccFR+8Fv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JDkuba/FashionMnist/blob/master/Notebooks/IRCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUPs2IJebS36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dce00fe5-7ad2-402b-9006-b3277627b631"
      },
      "source": [
        "# Synchronizacja z dyskiem\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "%cd './drive/My Drive/Projekt/FashionMnist'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Projekt/FashionMnist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz4Vd1erbuKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81393044-8d3e-478c-ee6f-d1fa1d4d9edb"
      },
      "source": [
        "#Importy i sprawdzenie czy mamy CUDA\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\"  \n",
        "dev"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXmXAFjTqzjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters = {\"batch_size\": 128,\n",
        "#               \"n_blocks\": 3,\n",
        "#               \"optimizer\": \"SGD\",\n",
        "#               \"optimizer_params\": {\"lr\": 0.02, \"momentum\": 0.9},\n",
        "#               \"patience\": 1,\n",
        "#               \"factor\": 0.1,\n",
        "#               \"n_epochs\": 32,\n",
        "#               \"name\": \"IRCNN_v0.1\"}\n",
        "# 32 loss: 0.036, accuracy: 99.18%\n",
        "# Accuracy of the network on test images: 91.56%\n",
        "\n",
        "# parameters = {\"batch_size\": 128,\n",
        "#               \"n_blocks\": 3,\n",
        "#               \"optimizer\": \"SGD\",\n",
        "#               \"optimizer_params\": {\"lr\": 0.02, \"momentum\": 0.9, \"weight_decay\": 1e-4},\n",
        "#               \"patience\": 1,\n",
        "#               \"factor\": 0.1,\n",
        "#               \"n_epochs\": 32,\n",
        "#               \"name\": \"IRCNN_v0.2\"}\n",
        "# 32 loss: 0.061, accuracy: 98.44%\n",
        "# Accuracy of the network on test images: 91.39%\n",
        "\n",
        "# parameters = {\"batch_size\": 128,\n",
        "#               \"n_blocks\": 3,\n",
        "#               \"optimizer\": \"SGD\",\n",
        "#               \"optimizer_params\": {\"lr\": 0.001, \"momentum\": 0.9, \"weight_decay\": 1e-4, 'nesterov': True},\n",
        "#               \"patience\": 1,\n",
        "#               \"factor\": 0.1,\n",
        "#               \"n_epochs\": 32,\n",
        "#               \"name\": \"IRCNN_v0.3\"}\n",
        "# 32 loss: 0.120, accuracy: 96.55%\n",
        "# Accuracy of the network on test images: 89.36%\n",
        "\n",
        "# parameters = {\"batch_size\": 128,\n",
        "#               \"n_blocks\": 3,\n",
        "#               \"optimizer\": \"Adam\",\n",
        "#               \"optimizer_params\": {\"lr\": 0.02},\n",
        "#               \"patience\": 1,\n",
        "#               \"factor\": 0.1,\n",
        "#               \"n_epochs\": 32,\n",
        "#               \"name\": \"IRCNN_v0.4\"}\n",
        "# 32 loss: 0.032, accuracy: 99.03%\n",
        "# Accuracy of the network on test images: 90.87%\n",
        "\n",
        "# parameters = {\"batch_size\": 128,\n",
        "#               \"n_blocks\": 3,\n",
        "#               \"optimizer\": \"Adam\",\n",
        "#               \"optimizer_params\": {\"lr\": 0.02, \"weight_decay\": 1e-4},\n",
        "#               \"patience\": 1,\n",
        "#               \"factor\": 0.1,\n",
        "#               \"n_epochs\": 32,\n",
        "#               \"name\": \"IRCNN_v0.5\"}\n",
        "# 32 loss: 0.219, accuracy: 92.46%, time: 19:07:26\n",
        "# Accuracy of the network on test images: 89.32%\n",
        "\n",
        "# parameters = {\"batch_size\": 128,\n",
        "#               \"n_blocks\": 3,\n",
        "#               \"optimizer\": \"AdamW\",\n",
        "#               \"optimizer_params\": { },\n",
        "#               \"patience\": 1,\n",
        "#               \"factor\": 0.1,\n",
        "#               \"n_epochs\": 32,\n",
        "#               \"name\": \"IRCNN_v0.6\"}\n",
        "# 32 loss: 0.070, accuracy: 97.71%, time: 19:35:06\n",
        "# Accuracy of the network on test images: 90.86%\n",
        "\n",
        "# parameters = {\"batch_size\": 128,\n",
        "#               \"n_blocks\": 3,\n",
        "#               \"optimizer\": \"AdamW\",\n",
        "#               \"optimizer_params\": { \"lr\": 0.02 },\n",
        "#               \"patience\": 1,\n",
        "#               \"factor\": 0.1,\n",
        "#               \"n_epochs\": 32,\n",
        "#               \"name\": \"IRCNN_v0.7\"}\n",
        "# 32 loss: 0.049, accuracy: 98.51%\n",
        "# Accuracy of the network on test images: 90.61%\n",
        "\n",
        "parameters = {\"batch_size\": 128,\n",
        "              \"n_blocks\": 3,\n",
        "              \"optimizer\": \"SGD\",\n",
        "              \"optimizer_params\": {\"lr\": 0.02, \"momentum\": 0.9},\n",
        "              \"patience\": 1,\n",
        "              \"factor\": 0.1,\n",
        "              \"n_epochs\": 32,\n",
        "              \"dropout\": 0.4,\n",
        "              \"name\": \"IRCNN_v0.8\"}\n",
        "# 32 loss: 0.032, accuracy: 99.19%\n",
        "# Accuracy of the network on test images: 91.89%"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGDHMoUIb2EB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#katalog, w którym przechowujemy dane\n",
        "root = \"data\"\n",
        "batch_size = parameters['batch_size']\n",
        "\n",
        "#transformacje wektorów wejściowych\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, ), (0.5, ))])\n",
        "\n",
        "train_dataset = dsets.FashionMNIST(root=root,\n",
        "                            train=True,\n",
        "                            transform=transform,\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.FashionMNIST(root=root,\n",
        "                            train=False,\n",
        "                            transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                shuffle=True)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4khdIrOccW6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RCL(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size):\n",
        "    super(RCL, self).__init__()\n",
        "    padding = 0 if kernel_size == 1 else 1\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
        "    self.bn2d1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.convr = nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding)\n",
        "    self.bn2dr = nn.BatchNorm2d(num_features=out_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    conv1 = self.conv1(x)\n",
        "    conv2 = self.convr(F.relu(self.bn2d1(conv1)))\n",
        "    x1 = conv1.add(conv2)\n",
        "    conv3 = self.convr(F.relu(self.bn2dr(x1)))\n",
        "    x1 = conv1.add(conv3)\n",
        "    conv4 = self.convr(F.relu(self.bn2dr(x1)))\n",
        "    x1 = conv1.add(conv4)\n",
        "    x1 = F.relu(self.bn2dr(x1))\n",
        "    return x1\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Block, self).__init__()\n",
        "    self.rcl1 = RCL(in_channels=64, out_channels=64, kernel_size=1)\n",
        "    self.rcl2 = RCL(in_channels=64, out_channels=128, kernel_size=3)\n",
        "    self.avgPool2d = nn.AvgPool2d(3, stride=1, padding=1)\n",
        "    self.rcl3 = RCL(in_channels=64, out_channels=64, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.rcl1(x)\n",
        "    x2 = self.rcl2(x)\n",
        "    x3 = self.rcl3(self.avgPool2d(x))\n",
        "    return torch.cat((x1, x2, x3), 1)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcS15bmWpFwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IRCNN(nn.Module):\n",
        "  def __init__(self, dropout=0.5):\n",
        "    super(IRCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "    self.bn2d2 = nn.BatchNorm2d(num_features=32)\n",
        "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "    self.bn2d3 = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "    self.block1 = Block()\n",
        "    self.conv_b1 = nn.Conv2d(in_channels=256, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn2d_b1 = nn.BatchNorm2d(num_features=64)\n",
        "    self.maxPool2d_b1 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "    self.dropout_b1 = nn.Dropout2d(p=dropout)\n",
        "\n",
        "    self.block2 = Block()\n",
        "    self.conv_b2 = nn.Conv2d(in_channels=256, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn2d_b2 = nn.BatchNorm2d(num_features=64)\n",
        "    self.maxPool2d_b2 = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "    self.dropout_b2 = nn.Dropout2d(p=dropout)\n",
        "\n",
        "    self.block3 = Block()\n",
        "    self.conv_b3 = nn.Conv2d(in_channels=256, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn2d_b3 = nn.BatchNorm2d(num_features=64)\n",
        "    self.globalAvgPool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.dropout_b3 = nn.Dropout2d(p=dropout)\n",
        "\n",
        "    self.dense1 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.conv1(x)\n",
        "    x1 = F.relu(self.bn2d2(self.conv2(x1)))\n",
        "    x1 = F.relu(self.bn2d3(self.conv3(x1)))\n",
        "    #\n",
        "    x1 = self.block1(x1)\n",
        "    x1 = self.conv_b1(x1)\n",
        "    x1 = self.bn2d_b1(x1)\n",
        "    x1 = self.maxPool2d_b1(x1)\n",
        "    x1 = self.dropout_b1(x1)\n",
        "    #\n",
        "    x1 = self.block2(x1)\n",
        "    x1 = self.conv_b2(x1)\n",
        "    x1 = self.bn2d_b2(x1)\n",
        "    x1 = self.maxPool2d_b2(x1)\n",
        "    x1 = self.dropout_b2(x1)\n",
        "    #\n",
        "    x1 = self.block3(x1)\n",
        "    x1 = self.conv_b3(x1)\n",
        "    x1 = self.bn2d_b3(x1)\n",
        "    x1 = self.globalAvgPool(x1)\n",
        "    x1 = self.dropout_b3(x1)\n",
        "    x1 = x1.view(x1.size(0), -1)\n",
        "    return self.dense1(x1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCpJOKcyKYFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"Change Runtime Type!\")\n",
        "\n",
        "dropout = parameters['dropout'] if 'dropout' in parameters else 0.5\n",
        "net = IRCNN(dropout=dropout)\n",
        "net.to(dev)\n",
        "\n",
        "save_path = \"saved_models/\" + parameters[\"name\"]\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if parameters['optimizer'] == 'SGD':\n",
        "  optimizer = optim.SGD(net.parameters(), **parameters['optimizer_params'])\n",
        "if parameters['optimizer'] == 'Adam':\n",
        "  optimizer = optim.Adam(net.parameters(), **parameters['optimizer_params'])\n",
        "if parameters['optimizer'] == 'AdamW':\n",
        "  optimizer = optim.AdamW(net.parameters(), **parameters['optimizer_params'])\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=parameters['factor'],\n",
        "                              patience=parameters['patience'], verbose=True)\n",
        "\n",
        "\n",
        "def accuracy(model, dataloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in dataloader:\n",
        "          images, labels = data\n",
        "          if torch.cuda.is_available():\n",
        "            images = images.to(dev)\n",
        "            labels = labels.to(dev)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "  return 100 * correct / total"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfErpieYNgM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "62c3f966-9ead-48b7-bd15-6db6895f4f05"
      },
      "source": [
        "best_accuracy = 0\n",
        "n_epochs = parameters['n_epochs']\n",
        "\n",
        "results = [] # list of tuples (epoch, loss, accuracy)\n",
        "\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    running_loss_n = 0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(dev)\n",
        "        labels = labels.to(dev)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_loss_n += 1\n",
        "\n",
        "    epoch_accuracy = accuracy(net, trainloader)\n",
        "    current_loss = running_loss / running_loss_n\n",
        "    results.append((epoch + 1, current_loss, epoch_accuracy))\n",
        "    print((f\"{epoch + 1} loss: {current_loss:.3f}, \"\n",
        "          f\"accuracy: {epoch_accuracy:.2F}%, \"))\n",
        "    \n",
        "    scheduler.step(epoch_accuracy)\n",
        "    if best_accuracy < epoch_accuracy:\n",
        "      best_accuracy = epoch_accuracy\n",
        "      torch.save((net.state_dict(), results), save_path)\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loss: 0.692, accuracy: 81.47%, \n",
            "2 loss: 0.457, accuracy: 86.11%, \n",
            "3 loss: 0.385, accuracy: 87.83%, \n",
            "4 loss: 0.340, accuracy: 88.65%, \n",
            "5 loss: 0.311, accuracy: 90.33%, \n",
            "6 loss: 0.292, accuracy: 90.28%, \n",
            "7 loss: 0.268, accuracy: 91.38%, \n",
            "8 loss: 0.251, accuracy: 91.82%, \n",
            "9 loss: 0.240, accuracy: 92.29%, \n",
            "10 loss: 0.228, accuracy: 92.48%, \n",
            "11 loss: 0.214, accuracy: 92.67%, \n",
            "12 loss: 0.205, accuracy: 93.60%, \n",
            "13 loss: 0.193, accuracy: 93.91%, \n",
            "14 loss: 0.184, accuracy: 94.33%, \n",
            "15 loss: 0.177, accuracy: 94.77%, \n",
            "16 loss: 0.167, accuracy: 94.88%, \n",
            "17 loss: 0.155, accuracy: 95.45%, \n",
            "18 loss: 0.148, accuracy: 95.73%, \n",
            "19 loss: 0.136, accuracy: 95.78%, \n",
            "20 loss: 0.130, accuracy: 96.12%, \n",
            "21 loss: 0.120, accuracy: 96.38%, \n",
            "22 loss: 0.118, accuracy: 96.38%, \n",
            "23 loss: 0.111, accuracy: 96.71%, \n",
            "24 loss: 0.100, accuracy: 96.88%, \n",
            "25 loss: 0.098, accuracy: 97.47%, \n",
            "26 loss: 0.090, accuracy: 96.87%, \n",
            "27 loss: 0.085, accuracy: 96.83%, \n",
            "Epoch    27: reducing learning rate of group 0 to 2.0000e-03.\n",
            "28 loss: 0.049, accuracy: 98.98%, \n",
            "29 loss: 0.033, accuracy: 99.24%, \n",
            "30 loss: 0.028, accuracy: 99.41%, \n",
            "31 loss: 0.023, accuracy: 99.43%, \n",
            "32 loss: 0.021, accuracy: 99.54%, \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrnpwNYWiHQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edc08be9-49f3-40ab-9f12-4813b6698108"
      },
      "source": [
        "params, results = torch.load(save_path)\n",
        "net.load_state_dict(params)\n",
        "print(f'Accuracy of the network on test images: {accuracy(net, testloader):.2F}%')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on test images: 91.89%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}