{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FractalNet.ipynb","provenance":[],"authorship_tag":"ABX9TyOzJpv7KfBIl5o0vAPbyvxB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"4i5QoShcUSkb","colab_type":"code","outputId":"fb0a80e0-d359-44c2-8f74-e6b5c09bdc05","executionInfo":{"status":"ok","timestamp":1591789755585,"user_tz":-120,"elapsed":41927,"user":{"displayName":"Mateusz Górski","photoUrl":"","userId":"14415938630392488223"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["# Synchronizacja z dyskiem\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","%cd './drive/My Drive/Projekt/FashionMnist'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive/Projekt/FashionMnist\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fXrlRvy6Ubue","colab_type":"code","outputId":"b5a9a328-609f-425a-86e8-5afc60445016","executionInfo":{"status":"ok","timestamp":1591789759366,"user_tz":-120,"elapsed":45691,"user":{"displayName":"Mateusz Górski","photoUrl":"","userId":"14415938630392488223"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Importy i sprawdzenie czy mamy CUDA\n","import torch\n","import torchvision\n","\n","if torch.cuda.is_available():  \n","  dev = \"cuda:0\" \n","else:  \n","  dev = \"cpu\"  \n","dev"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda:0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"96gIjEWCCwtw","colab_type":"code","colab":{}},"source":["# parameters = {\"batch_size\": 100,\n","#               \"kernel_size\": 3,\n","#               \"padding\": 1, # dla kernel_size = 3 nie zmieni wielkości obrazka\n","#               \"C\": 4,\n","#               \"n_blocks\": 4,\n","#               \"channels\": [1, 16, 64, 128, 256],\n","#               \"lr\": 0.02,\n","#               \"patience\": 2,\n","#               \"factor\": 0.1,\n","#               \"n_epochs\": 40,\n","#               \"dropouts\": [0, 0.1, 0.2, 0.2],\n","#               \"linear_size2\": 64,\n","#               \"name\": \"Fractal_v0.1\"}\n","# Accuracy of the network on test images: 89.88 %\n","\n","# parameters = {\"batch_size\": 100,\n","#               \"kernel_size\": 3,\n","#               \"padding\": 1, # dla kernel_size = 3 nie zmieni wielkości obrazka\n","#               \"C\": 4,\n","#               \"n_blocks\": 4,\n","#               \"channels\": [1, 16, 64, 128, 256],\n","#               \"lr\": 0.02,\n","#               \"patience\": 1,\n","#               \"factor\": 0.1,\n","#               \"n_epochs\": 30,\n","#               \"dropouts\": [0, 0.1, 0.1, 0.1],\n","#               \"linear_size2\": 64,\n","#               \"name\": \"Fractal_v0.2\"}\n","# Accuracy of the network on test images: 90.39 %\n","\n","# parameters = {\"batch_size\": 100,\n","#               \"kernel_size\": 3,\n","#               \"padding\": 1, # dla kernel_size = 3 nie zmieni wielkości obrazka\n","#               \"C\": 4,\n","#               \"n_blocks\": 4,\n","#               \"channels\": [1, 16, 64, 128, 256],\n","#               \"lr\": 0.02,\n","#               \"patience\": 1,\n","#               \"factor\": 0.1,\n","#               \"n_epochs\": 30,\n","#               \"dropouts\": [0, 0.1, 0.1, 0.1],\n","#               \"name\": \"Fractal_v0.3\"}\n","# 29 loss: 0.212 train accuracy: 93.16 % \n","# Accuracy of the network on test images: 90.77 %\n","\n","# parameters = {\"batch_size\": 100,\n","#               \"kernel_size\": 3,\n","#               \"padding\": 1, # dla kernel_size = 3 nie zmieni wielkości obrazka\n","#               \"C\": 4,\n","#               \"n_blocks\": 4,\n","#               \"channels\": [1, 8, 64, 128, 256],\n","#               \"lr\": 0.02,\n","#               \"patience\": 1,\n","#               \"factor\": 0.1,\n","#               \"n_epochs\": 30,\n","#               \"dropouts\": [0, 0.1, 0.1, 0.1],\n","#               \"name\": \"Fractal_v0.4\"}\n","# Accuracy of the network on test images: 89.47 %\n","\n","parameters = {\"batch_size\": 100,\n","              \"kernel_size\": 3,\n","              \"padding\": 1, # dla kernel_size = 3 nie zmieni wielkości obrazka\n","              \"C\": 4,\n","              \"n_blocks\": 4,\n","              \"channels\": [1, 16, 64, 128, 256],\n","              \"lr\": 0.02,\n","              \"patience\": 1,\n","              \"factor\": 0.1,\n","              \"n_epochs\": 35,\n","              \"dropouts\": [0, 0.1, 0.1, 0.2],\n","              \"name\": \"Fractal_v0.31\"}\n","# Accuracy of the network on test images: 91.25 %\n","# 32 loss: 0.225 train accuracy: 92.29 %"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"syNmqtfGUj_s","colab_type":"code","colab":{}},"source":["import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","# Katalog, w którym przechowujemy dane\n","root = \"data\"\n","batch_size = parameters[\"batch_size\"]\n","\n","# Transformacje wektorów wejściowych\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5, ), (0.5, ))])\n","\n","#ładowanie danych\n","train_dataset = dsets.FashionMNIST(root=root,\n","                            train=True,\n","                            transform=transform,\n","                            download=True)\n","\n","test_dataset = dsets.FashionMNIST(root=root,\n","                            train=False,\n","                            transform=transform)\n","\n","trainloader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                                batch_size=batch_size,\n","                                                shuffle=True)\n","\n","testloader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                                batch_size=batch_size,\n","                                                shuffle=True) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VAV-ypBsXNde","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FOU35eSOaa1V","colab_type":"code","colab":{}},"source":["kernel_size = parameters[\"kernel_size\"]\n","padding = parameters[\"padding\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSU_j9uBJx08","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","class DropPath(nn.Module):\n","  # Klasa implementująca drop-path opisany w pracy (dział 3.1)\n","  # Z tym samym prawdopodobiestwem wybierana jest strategia\n","  # \"Local\" i \"Global\"\n","\n","  # Parametr `p` określa prawdopodobieństwo, z jakim każdy z inputów\n","  # będzie odrzucony, przy czym przynajmniej jedna ze ścieżek musi zostać\n","  # wybrana. Parametr jest wykorzystywany jedynie w strategii \"Local\"\n","  # `C` oznacza liczbę kolumn w jednym bloku sieci Fractal\n","  def __init__(self, p, C):\n","    super(DropPath, self).__init__()\n","    self.C = C\n","    self.p = p\n","\n","  def prepare(self):\n","    self.is_global = np.random.choice([True, False])\n","    if self.is_global:\n","      self.allowed = np.random.choice(np.arange(1, self.C + 1))\n","\n","  # TODO: wymyślić coś żeby w przypadku local była przynajmniej jedna\n","  # aktywna ścieżka\n","  def forward(self, x, column = None):\n","    if not self.training:\n","      return x\n","    if self.is_global:\n","      if column == self.allowed:\n","        return x\n","      else:\n","        return torch.zeros_like(x)\n","    if np.random.random() < self.p:\n","      return torch.zeros_like(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rau7kHy8XPQ8","colab_type":"code","colab":{}},"source":["'''\n","Szczegóły implementacji są w dziale 3.3.\n","* \"As now standard, we employ batch normalization together with each conv layer \n","  (convolution, batch norm, then ReLU).\"\n","'''\n","\n","class Fractal(nn.Module):\n","  # Klasa implementuje blok \"f_C\" z pracy (dział 3)\n","\n","  # parametr `n_channels` określa liczbę kanałów pomiędzy\n","  # kolejnymi `f_i`; np dla C = 1 mamy\n","  # n_channels = [in_channels, out_channels]\n","  # dropPath - instancja klasy DropPath w bloku, do którego należy Fractal\n","  def __init__(self, C, in_channels, out_channels, dropPath, dropout):\n","    super(Fractal, self).__init__()\n","    self.C = C\n","    self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n","    self.bn2d = nn.BatchNorm2d(out_channels)\n","    self.dropPath = dropPath\n","    self.dropout = nn.Dropout2d(dropout)\n","\n","    if C > 1:\n","      self.fC1 = Fractal(C - 1, in_channels, out_channels, dropPath, dropout)\n","      self.fC2 = Fractal(C - 1, out_channels, out_channels, dropPath, dropout)\n","    \n","  def forward(self, x):\n","    x1 = self.dropPath(F.relu(self.bn2d(self.conv2d(x))), self.C)\n","    x1 = self.dropout(x1)\n","    if self.C > 1:\n","      x2 = self.fC2(self.fC1(x))\n","      x1 = torch.mean(torch.stack([x1, x2]), 0) # join\n","    return x1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IzGtBGm6UqMe","colab_type":"code","colab":{}},"source":["class Block(nn.Module):\n","  # Klasa implementuje budowę bloku, oraz zawiera w sobie rekurencyjne\n","  # tworzenie kolejnego\n","\n","  # C jest parametrem określającym liczbę kolumn w danym bloku\n","  # n_block oznacza numer bloku (ten na samym dole na numer 0)\n","  # channels określa liczbę kanałów kolejno wejściowych i wyjściowych\n","  #   każdego bloku\n","  def __init__(self, C, n_block, channels, p, dropouts):\n","    super(Block, self).__init__()\n","\n","    self.dropPath = DropPath(p[0], C)\n","    self.fractal = Fractal(C, channels[0], channels[1], self.dropPath, dropouts[0])\n","    self.n_block = n_block\n","    \n","    if self.n_block > 0:\n","      self.next_block = Block(C, n_block - 1, channels[1:], p[1:], dropouts[1:])\n","\n","    self.pool = nn.MaxPool2d(2, 2)\n","\n","  def forward(self, x):\n","    self.dropPath.prepare()\n","    x = self.pool(self.fractal(x))\n","    if self.n_block > 0:\n","      x = self.next_block(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eh2DaZrQeyE0","colab_type":"code","colab":{}},"source":["class FractalNet(nn.Module):\n","  # C jest parametrem określającym liczbę kolumn w danym bloku\n","  # n_blocks oznacza liczbę bloków\n","  # channels określa liczbę kanałów kolejno wejściowych i wyjściowych\n","  #   każdego bloku\n","  # len(channels) = n_blocks + 1\n","  def __init__(self, C, n_blocks, channels, droppath_p, dropouts):\n","    super(FractalNet, self).__init__()\n","\n","    if len(channels) != n_blocks + 1:\n","      raise RuntimeError(\"Niepoprawny rozmiar tablicy `channels`.\")\n","    if len(droppath_p) != n_blocks:\n","      raise RuntimeError(\"Niepoprawny rozmiar tablicy `droppath_p`.\")\n","\n","    self.block = Block(C, n_blocks - 1, channels, droppath_p, dropouts)\n","\n","    image_size = 28\n","    output_size = int(image_size / int(2 ** n_blocks))\n","    self.linearSize1 = (output_size ** 2) * channels[-1]\n","    # self.linearSize2 = parameters[\"linear_size2\"]\n","\n","    self.dense1 = nn.Linear(self.linearSize1, 10)\n","    # self.dense1 = nn.Linear(self.linearSize1, self.linearSize2)\n","    # self.dense2 = nn.Linear(self.linearSize2, 10)\n","\n","  def forward(self, x):\n","    x = self.block(x)\n","    x = x.view(-1, self.linearSize1)\n","    x = self.dense1(x)\n","    # x = self.dense2(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pxclM2xwBS3w","colab_type":"code","colab":{}},"source":["net = FractalNet(parameters[\"C\"], \n","                 parameters[\"n_blocks\"], \n","                 parameters[\"channels\"], \n","                 [0.15, 0.15, 0.15, 0.15],\n","                 parameters[\"dropouts\"])\n","# jeżeli można, używamy CUDA\n","if torch.cuda.is_available():\n","  net.to(\"cuda:0\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1LFUOssSuQo","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=parameters[\"lr\"], momentum=0.9)\n","scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=parameters[\"factor\"],\n","                              patience=parameters[\"patience\"], verbose=True)\n","\n","\n","def accuracy(model, dataloader):\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():\n","      for data in dataloader:\n","          images, labels = data\n","          if torch.cuda.is_available():\n","            images = images.to(\"cuda:0\")\n","            labels = labels.to(\"cuda:0\")\n","          outputs = model(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","  return 100 * correct / total"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Do8hyYP75i5r","colab_type":"code","colab":{}},"source":["save_path = \"saved_models/\" + parameters[\"name\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9_-G4L3VTstQ","colab_type":"code","outputId":"b5901166-0203-4516-9c23-d0df5ba715eb","executionInfo":{"status":"error","timestamp":1591559268556,"user_tz":-120,"elapsed":25121,"user":{"displayName":"Mateusz Górski","photoUrl":"","userId":"14415938630392488223"}},"colab":{"base_uri":"https://localhost:8080/","height":364}},"source":["n_epochs = parameters[\"n_epochs\"] + 10\n","best_accuracy = 0\n","\n","for epoch in range(n_epochs):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    running_loss_n = 0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        if torch.cuda.is_available():\n","          inputs = inputs.to(\"cuda:0\")\n","          labels = labels.to(\"cuda:0\")\n","\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        running_loss_n += 1\n","    epoch_accuracy = accuracy(net, trainloader)\n","    print('%d loss: %.3f train accuracy: %.2f %%' %\n","                   (epoch + 1, running_loss / running_loss_n, \n","                    epoch_accuracy))\n","    scheduler.step(epoch_accuracy)\n","\n","    if best_accuracy < epoch_accuracy:\n","      best_accuracy = epoch_accuracy\n","      torch.save(net.state_dict(), save_path)\n","\n","print('Finished Training')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1 loss: 1.098 train accuracy: 73.60 %\n","2 loss: 0.595 train accuracy: 80.11 %\n","3 loss: 0.520 train accuracy: 83.50 %\n","4 loss: 0.444 train accuracy: 85.58 %\n","5 loss: 0.409 train accuracy: 85.61 %\n","6 loss: 0.401 train accuracy: 86.89 %\n","7 loss: 0.356 train accuracy: 88.32 %\n","8 loss: 0.344 train accuracy: 87.76 %\n","9 loss: 0.347 train accuracy: 88.59 %\n","10 loss: 0.330 train accuracy: 89.16 %\n","11 loss: 0.300 train accuracy: 88.70 %\n","12 loss: 0.296 train accuracy: 89.42 %\n","13 loss: 0.305 train accuracy: 89.49 %\n","14 loss: 0.298 train accuracy: 90.19 %\n","15 loss: 0.289 train accuracy: 90.41 %\n","16 loss: 0.274 train accuracy: 90.47 %\n","17 loss: 0.284 train accuracy: 90.32 %\n","18 loss: 0.265 train accuracy: 90.52 %\n","19 loss: 0.287 train accuracy: 90.29 %\n","20 loss: 0.249 train accuracy: 90.60 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TTrqOIH0YwR5","colab_type":"code","colab":{}},"source":["net.load_state_dict(torch.load(save_path))\n","print('Accuracy of the network on test images: %.2f %%' % (\n","    accuracy(net, testloader)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y0qlK_KD9kDp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}